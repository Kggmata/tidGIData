created: 20220725073006040
modified: 20220725073237742
tags: ? flink
title: 数据计算模型
type: text/vnd.tiddlywiki

```
4.2.2 	数据计算模型
● Hudi是Uber主导开发的开源数据湖框架，所以大部分的出发点都来源于 Uber 自身场景，比如司机数据和乘客数据通过订单Id来做Join等。
● 在Hudi过去的使用场景里，和大部分公司的架构类似，采用批式和流式共存的Lambda架构，后来Uber提出增量Incremental模型，相对批式来讲，更加实时；相对流式而言，更加经济。
```
[img[BillfishirZynV2022-07-25 15_31_00.PNG]]

```
4.2.2.1 	批式模型（Batch）
批式模型就是使用MapReduce、Hive、Spark等典型的批计算引擎，以小时任务或者天任务的形式来做数据计算。
■ 1、延迟：小时级延迟或者天级别延迟。这里的延迟不单单指的是定时任务的时间，在数据架构里， 这里的延迟时间通常是定时任务间隔时间+一系列依赖任务的计算时间+数据平台最终可以展示结果的时间。数据量大、逻辑复杂的情况下，小时任务计算的数据通常真正延迟的时间是2-3小时。
■ 2、数据完整度：数据较完整。以处理时间为例，小时级别的任务，通常计算的原始数据已经包含了小时内的所有数据，所以
得到的数据相对较完整。但如果业务需求是事件时间，这里涉及到终端的一些延迟上报机制，在这里，批式计算任务就很难派上用场。
■ 3、成本：成本很低。只有在做任务计算时，才会占用资源，如果不做任务计算，可以将这部分批式计算资源出让给在线业务使用。从另一个角度来说成本是挺高的，如原始数据做了一些增删改查，数据晚到的情况，那么批式任务是要全量重新计算。
```
[img[BillfishjMYiuG2022-07-25 15_31_31.PNG]]

```
4.2.2.2 	流式模型（Stream）
流式模型，典型的就是使用Flink来进行实时的数据计算。
■ 1、延迟：很短，甚至是实时。
■ 2、数据完整度：较差。因为流式引擎不会等到所有数据到齐之后再开始计算，所以有一个 watermark 的概念，当数据的时间小于watermark 时，就会被丢弃，这样是无法对数据完整度有一个绝对的报障。在互联网场景中，流式模型主要用于活动时的数据大盘展示，对数据的完整度要求并不算很高。在大部分场景中，用户需要开发两个程序，一是流式数据生产流式结果，二是批式计算任务，用于次日修复实时结果。
■ 3、成本：很高。因为流式任务是常驻的，并且对于多流Join的场景，通常要借助内存或者数据库来做state的存储，不管是序列化开销，还是和外部组件交互产生的额外IO，在大数据量下都是不容忽视的。
```
[img[BillfishxkQAqv2022-07-25 15_31_56.PNG]]

```
4.2.2.3 	增量模型（Incremental）
● 针对批式和流式的优缺点，Uber提出了增量模型（Incremental Mode），相对批式来讲，更加实时；相对流式而言，更加经济。
● 增量模型，简单来讲，是以mini batch的形式来跑准实时任务。Hudi在增量模型中支持了两个最重要的特性：
■ 1、Upsert：这个主要是解决批式模型中，数据不能插入、更新的问题，有了这个特性，可以往 Hive 中写入增量数据，而不是每次进行完全的覆盖。（Hudi自身维护了key->file的映射，所以当upsert时很容易找到key对应的文件）
■ 2、Incremental Query：增量查询，减少计算的原始数据量。以Uber中司机和乘客的数据流Join 为例，每次抓取两条数据流中的增量数据进行批式的Join即可，相比流式数据而言，成本要降低几个数量级。
```
[img[BillfishLVgqZv2022-07-25 15_32_21.PNG]]