created: 20220628225904403
creator: Yangqing QU
difficulty: 2.2127681787299665
due: 20221218111112995
grade: 0
history: [{"due":"20220630135408974","interval":0,"difficulty":0.2875876480092351,"stability":0.10000181198120117,"retrievability":1,"grade":-1,"lapses":0,"reps":1,"review":"20220629135408974"},{"due":"20220720123117244","interval":5,"difficulty":1,"stability":16.307105289069998,"retrievability":0.005154267178780677,"grade":1,"lapses":0,"reps":2,"review":"20220704123117244"},{"due":"20220727113855154","interval":22,"difficulty":2.067497702097154,"stability":0.07408186401656833,"retrievability":0.8674977020971539,"grade":0,"lapses":1,"reps":1,"review":"20220726113855153"},{"due":"20220804074001594","interval":8,"difficulty":2.267509149597526,"stability":0.054881171378436774,"retrievability":0.000011447500371767003,"grade":0,"lapses":2,"reps":1,"review":"20220803074001594"},{"due":"20220818112152206","interval":5,"difficulty":1,"stability":10.16456942996506,"retrievability":0.00006779870516182631,"grade":2,"lapses":2,"reps":2,"review":"20220808112152205"},{"due":"20220829114345986","interval":20,"difficulty":2.0127681787299663,"stability":0.040656966333775045,"retrievability":0.8127681787299662,"grade":0,"lapses":3,"reps":1,"review":"20220828114345985"}]
interval: 111
lapses: 4
modified: 20230102012807706
modifier: Yangqing QU
reps: 1
retrievability: 1.1878338242945895e-125
review: 20221217111112995
stability: 0.6023884238244042
tags: ? stream实时/kafka
title: kafka如何解决leader replica宕机时数据丢失的问题
type: text/vnd.tiddlywiki

kafka中HW（High Watermark）有两个作用

```
一是用来表示哪些消息可以被消费者消费，相当于分界线

二是帮助kafka完成副本的同步

```

https://cloud.tencent.com/developer/article/1803023

```
HW （High Watermark）俗称高水位，它标识了一个特定的消息偏移量（offset），消费者只能拉取到这个offset之前的消息。

下图表示一个日志文件，这个日志文件中只有9条消息，第一条消息的offset（LogStartOffset）为0，最有一条消息的offset为8，offset为9的消息使用虚线表示的，代表下一条待写入的消息。日志文件的 HW 为6，表示消费者只能拉取offset在 0 到 5 之间的消息，offset为6的消息对消费者而言是不可见的。
```

[img[Kafka中的HW、LEO、LSO等分别代表什么？ - 腾讯云开2022-06-29 07_03_48.png]]

```
LEO （Log End Offset），标识当前日志文件中下一条待写入的消息的offset。上图中offset为9的位置即为当前日志文件的 LEO，LEO 的大小相当于当前日志分区中最后一条消息的offset值加1.分区 ISR 集合中的每个副本都会维护自身的 LEO ，而 ISR 集合中最小的 LEO 即为分区的 HW，对消费者而言只能消费 HW 之前的消息。
```
```
下面具体分析一下 ISR 集合和 HW、LEO的关系。

假设某分区的 ISR 集合中有 3 个副本，即一个 leader 副本和 2 个 follower 副本，此时分区的 LEO 和 HW 都分别为 3 。消息3和消息4从生产者出发之后先被存入leader副本。
```
[img[Kafka中的HW、LEO、LSO等分别代表什么？ - 腾讯云开2022-06-29 07_08_28.png]]

[img[Kafka中的HW、LEO、LSO等分别代表什么？ - 腾讯云开_3c0b33082022-06-29 07_08_31.png]]

```
在消息被写入leader副本之后，follower副本会发送拉取请求来拉取消息3和消息4进行消息同步。

在同步过程中不同的副本同步的效率不尽相同，在某一时刻follower1完全跟上了leader副本而follower2只同步了消息3，如此leader副本的LEO为5，follower1的LEO为5，follower2的LEO 为4，那么当前分区的HW取最小值4，此时消费者可以消费到offset0至3之间的消息。
```
[img[Kafka中的HW、LEO、LSO等分别代表什么？ - 腾讯云开2022-06-29 07_09_00.png]]

```
当所有副本都成功写入消息3和消息4之后，整个分区的HW和LEO都变为5，因此消费者可以消费到offset为4的消息了。
```
[img[Kafka中的HW、LEO、LSO等分别代表什么？ - 腾讯云开2022-06-29 07_09_25.png]]

```
由此可见kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。事实上，同步复制要求所有能工作的follower副本都复制完，这条消息才会被确认已成功提交，这种复制方式极大的影响了性能。而在异步复制的方式下，follower副本异步的从leader副本中复制数据，数据只要被leader副本写入就会被认为已经成功提交。在这种情况下，如果follower副本都还没有复制完而落后于leader副本，然后leader副本宕机，则会造成数据丢失。kafka使用这种ISR的方式有效的权衡了数据可靠性和性能之间的关系。
```