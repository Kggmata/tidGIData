created: 20220606113545110
difficulty: 1.0684973211750646
due: 20221002001904445
grade: 1
history: [{"due":"20220611003600849","interval":0,"difficulty":1.2687524673440806,"stability":0.1037109375,"retrievability":1,"grade":-1,"lapses":0,"reps":1,"review":"20220610003600849"},{"due":"20220629235238805","interval":3,"difficulty":1,"stability":15.693018113617368,"retrievability":0.04746718678804762,"grade":2,"lapses":0,"reps":2,"review":"20220613235238805"}]
interval: 21
lapses: 0
modified: 20220705001904445
reps: 3
retrievability: 0.8684973211750646
review: 20220705001904444
stability: 88.53436204041341
tags: hbase ?
title: rowkey分区设计总结
type: text/vnd.tiddlywiki

```
1. 直接分,比如随机数字的,或者字母等比较好找规律,容易负载均衡的

2. rowkey反转,比如手机号默认顺序不好负载均匀,反转过来可以解决

3. 随机数,比如加随机前缀,或者hash散列比如md5 sha1,将rowkey变成16进制字符串,比如MD5加密后，就可以应用HBase提供的`HexStringSplit（16进制字符串）`自动分区功能。
```

''对于范围扫描''

```
1 如果能有组合Rowkey的可能，就使用组合Rowkey

比如，以存储用户的订单为例：

Rowkey可以设计为： 用户ID_时间

2 如果，我不想锁定某一个用户，我只想`查询一段时间范围`的数据：

userid_时间，的设计就不满足要求了。

最好的查询设计，就是直接拿时间作为Rowkey，这样范围查询和单条都很快。

这样设计，写入的时候：会造成热点问题。

也即是线性增长的数据（比如时间），在写入的时候，会造成逮着一个分区可劲写（热点分区）

> 对于这种类型的问题，让它热点
>
> 明确需求：
>
> - 为了查
> - 还是为了写
>
> 可以接受写入的热点，只要查询的时候足够快，是可以接受的。
```

实例

```
1. 根据航班号，找一定时间范围的这个航班的数据

   表1：rowkey：航班号_时间

2. 根据时间，查询这一段时间内的全部航班数据

   表2：Rowkey：时间（天分区提前规划好了）

   持续的热点写入，在某个时间段内，怼一个region

   查询的时候真香
```

目的是查询，写入热点无法接受

```
写入的时候数据量过大（1小时1个TB），哪怕我忍受热点，hbase 扛不住，内存报错，HFile合并堆压

如果热点能稳定的跑下去，那么就没关系，但是无法稳定的跑我们就需要换方式。

解决方式1（土豪专享）：加内存，加CPU

解决方式2：二级缓存（索引）

按照完全分散的模式，将数据写入，额外找一张表，记录你要查询的范围，对应的Rowkey是哪些
```

> 总结：通过额外的一张表，去记录你想要的查询条件的Rowkey在数据表中的分布
>
> 二级索引的表不一定记录在HBase中，你可以找任何你认为性能更加强力的存储，比如Redis

> Redis：只要数据量`不大`，快到HBase都不敢和我比较，
>
> Redis：内存缓存数据库

[img[20220606161222.png]]



