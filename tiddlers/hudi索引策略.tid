created: 20220725065440758
modified: 20220725065619703
tags: ? flink
title: hudi索引策略
type: text/vnd.tiddlywiki

```
3.4.1.1 	工作负载 1：对事实表
● 许多公司将大量事务数据存储在 NoSQL 数据存储中。例如，拼车情况下的行程表、股票买卖、电子商务网站中的订单。这些表通常会随着对最新数据的随机更新而不断增长，而长尾更新会针对较旧的数据，这可能是由于交易在以后结算/数据更正所致。换句话说，大多数更新进入最新的分区，很少有更新进入较旧的分区。
```
[img[BillfishQbvjyR2022-07-25 14_55_15.PNG]]

```
图1：事实表的典型更新模式
● 对于这样的工作负载，BLOOM 索引表现良好，因为索引查找 将基于大小合适的布隆过滤器修剪大量数据文件。此外，如果可以构造键以使它们具有一定的顺序，则要比较的文件数量会通过范围修剪进一步减少。
● Hudi 使用所有文件键范围构建一个区间树，并有效地过滤掉更新/删除记录中与任何键范围不匹配的文件。
● 为了有效地将传入的记录键与布隆过滤器进行比较，即最小数量的布隆过滤器读取和跨执行程序的统一工作分配，Hudi 利用输入记录的缓存并采用可以使用统计信息消除数据偏差的自定义分区器。有时，如果布隆过滤器误报率很高，它可能会增加混洗的数据量以执行查找。
● Hudi 支持动态布隆过滤器（使用启用 hoodie.bloom.index.filter.type=DYNAMIC_V0），它根据存储在给定文件中的记录数调整其大小，以提供配置的误报率。
```
```
3.4.1.2 	工作负载 2：对事件表
● 事件流无处不在。来自 Apache Kafka 或类似消息总线的事件通常是事实表大小的 10-100 倍，并且通常将 时间（事件的到达时间/处理时间）视为一等公民。
● 例如，**物联网事件流、点击流数据、广告印象 **等。插入和更新仅跨越最后几个分区，因为这些大多是仅附加数据。鉴于可以在端到端管道中的任何位置引入重复事件，因此在存储到数据湖之前进行重复数据删除是一项常见要求。
```
[img[BillfishTDvenf2022-07-25 14_55_46.PNG]]

```
● 一般来说，这是一个非常具有挑战性的问题，需要以较低的成本解决。虽然，我们甚至可以使用键值存储来使用 HBASE 索引执行重复数据删除，但索引存储成本会随着事件的数量线性增长，因此可能会非常昂贵。
● 实际上，BLOOM 带有范围修剪的索引是这里的最佳解决方案。人们可以利用时间通常是一等公民这一事实并构造一个键，event_ts + event_id 例如插入的记录具有单调递增的键。即使在最新的表分区中，也可以通过修剪大量文件来产生巨大的回报。
```
```
3.4.1.3 	工作负载 3：随机更新/删除维度表
● 这些类型的表格通常包含高维数据并保存参考数据，例如 用户资料、商家信息。这些是高保真表，其中更新通常很小，但也分布在许多分区和数据文件中，数据集从旧到新。通常，这些表也是未分区的，因为也没有对这些表进行分区的好方法。
● 如前所述，BLOOM 如果无法通过比较范围/过滤器来删除大量文件，则索引可能不会产生好处。在这样的随机写入工作负载中，更新最终会触及表中的大多数文件，因此布隆过滤器通常会根据一些传入的更新指示所有文件的真阳性。因此，我们最终会比较范围/过滤器，只是为了最终检查所有文件的传入更新。
● SIMPLE 索引将更适合，因为它不进行任何基于预先修剪的操作，而是直接与每个数据文件中感兴趣的字段连接 。HBASE 如果操作开销是可接受的，并且可以为这些表提供更好的查找时间，则可以使用索引。
● 在使用全局索引时，用户还应该考虑设置 hoodie.bloom.index.update.partition.path=true或hoodie.simple.index.update.partition.path=true 处理分区路径值可能因更新而改变的情况，例如用户表按家乡分区；用户搬迁到不同的城市。这些表也是 Merge-On-Read 表类型的绝佳候选者。
```