created: 20220607055949823
difficulty: 1
due: 20220926144739557
grade: 2
history: [{"due":"20220611235030136","interval":0,"difficulty":1.2687524673440806,"stability":0.1037109375,"retrievability":1,"grade":-1,"lapses":0,"reps":1,"review":"20220610235030136"},{"due":"20220630003643795","interval":3,"difficulty":1,"stability":15.693018113617368,"retrievability":0.04746718678804762,"grade":2,"lapses":0,"reps":2,"review":"20220614003643795"}]
interval: 19
lapses: 0
modified: 20220703144739557
reps: 3
retrievability: 0.8802378846142273
review: 20220703144739557
stability: 84.76492027716989
tags: hbase ?
title: 现在有一个10TB的文件（CSV），如何对文件进行处理，让其可以在很短的时间内从文件内找出特定的一条数据？  > 备注：这个题是我以前面试的时候遇到的，可以参考HBase的设计解决
type: text/vnd.tiddlywiki

现在有一个10TB的文件（CSV），如何对文件进行处理，让其可以在很短的时间内从文件内找出特定的一条数据？

> 备注：这个题是我以前面试的时候遇到的，可以参考HBase的设计解决

> HBase的设计思路是`通用思路`，可以用在海量数据下，快速的随机查询要求
>
> HBase的设计来自谷歌发布的BigTable论文，我们下面提供的思路，就是BigTable论文中提供的通用解决方案



1. 将文件，进行排序
2. 将文件等分成多个文件，比如100个（类似HBase的Region），每个文件就出现范围了
3. 每个小文件，都是有序的，单条查询就很快（类似HBase的HFile）





> 通用思路就是：
>
> 1. 大文件分散成非常多小文件
> 2. 确保小文件内部数据有序

