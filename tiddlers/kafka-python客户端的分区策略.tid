created: 20220611062307563
difficulty: 1
due: 20220915124326454
grade: 2
history: [{"due":"20220614110644688","interval":0,"difficulty":1.0984764469154382,"stability":0.10185546875000001,"retrievability":1,"grade":-1,"lapses":0,"reps":1,"review":"20220613110644688"},{"due":"20220617045140467","interval":3,"difficulty":1.3433801103128513,"stability":0.07425364270040997,"retrievability":0.04490366339741324,"grade":0,"lapses":1,"reps":1,"review":"20220616045140467"},{"due":"20220630113324312","interval":2,"difficulty":1,"stability":11.792887567465318,"retrievability":0.05855115497747565,"grade":1,"lapses":1,"reps":2,"review":"20220618113324311"}]
interval: 16
lapses: 1
modified: 20230102012807706
modifier: Yangqing QU
reps: 3
retrievability: 0.866799247229585
review: 20220704124326453
stability: 73.33880426530696
tags: stream实时/kafka ?
title: kafka-python客户端的分区策略
type: text/vnd.tiddlywiki

*默认情况下

当我们使用kafka-python库的时候，默认情况下就是使用的Kafka内置的：`Partitioner`，随机分发

[img[20220611112658.png]]

>只要没特殊需求，无脑选择随机模式，也就是啥事不干。

*手动选择分区写入

[img[20220611112736.png]]

在kafka-python库，调用send方法发送数据到kafka的时候，可以通过partition参数，来手动确定分区。

> 一定要注意，如果参数你写固定，那么数据将只写入1个固定分区





*实际案例

> 有5台Kafka，其中3台是32核CPU，有2台是8核CPU
>
> 所以当时，是通过手动选择分区，通过算法（随机数）来随机0~4的分区，
>
> 确保落入0、1、2的分区的随机数的权重是，分区3和4的4倍
>
> 目的是让3台服务器的数据是2台低配的4倍。
>
> [img[20220611114258.png]]

*Key Hash选择分区

kafka-python库，也支持通过数据的`key`来选择分区，策略是：

- 对key进行Hash计算，对分区号进行Hash取余数，得到分区号

> 结论：`相同的key将落入同一个分区`，不同的key可能在一个分区内，也可能在不同分区。



> 和Spark的分区规则一样，如果key不均衡，key倾斜了，也会导致Kafka的分区数据倾斜

> 这是高级用法，一般不用
>
> 我们完全随机写入分区即可。
>
> 为什么不用呢，因为：kafka不是数据库，也不做数据计算（在消息队列的场景下）
>
> 数据在哪个分区下，无所谓，反正就会找到开始的offset，按顺序消费即可。



如何使用：

在send方法内，传入key值即可：
[img[20220611113603.png]]
[img[20220611113457.png]][img[20220611113445-165492877406613.png]]

