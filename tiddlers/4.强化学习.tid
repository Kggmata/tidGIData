created: 20220625021208799
difficulty: 1.0778592709133121
due: 20221010071441976
grade: 1
history: [{"due":"20220630084742428","interval":0,"difficulty":0.2875876480092351,"stability":0.10000181198120117,"retrievability":1,"grade":-1,"lapses":0,"reps":1,"review":"20220629084742428"},{"due":"20220717123948262","interval":3,"difficulty":1,"stability":15.367048766557211,"retrievability":0.04239358618575581,"grade":2,"lapses":0,"reps":2,"review":"20220702123948262"}]
interval: 19
lapses: 0
modified: 20221210005806765
modifier: Yangqing QU
reps: 3
retrievability: 0.8778592709133122
review: 20220721071441976
stability: 81.17572220252381
tags: userProfile用户画像 ?
title: 4.强化学习
type: text/vnd.tiddlywiki

强化学习是在算法必经的多个阶段附加奖励值的方法。因此，该模型的目标是积累尽可能多的奖励积分，并实现最终目标。在过去的 10 年间，强化学习的大多实际应用都在电子游戏领域。先进的强化学习算法在经典和现代游戏中都取得了令人印象深刻的结果，往往大大超越人类的能力。 

这种方法在不确定且复杂的数据环境中表现非常好，但在商业环境中却很少得到应用。该方法对于预先定义好的任务而言效率较低，并且开发人员的偏好也会影响结果。这是因为数据科学家设计了奖励，它们可以影响结果。