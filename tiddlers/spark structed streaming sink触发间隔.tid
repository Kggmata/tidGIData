created: 20220612112829684
difficulty: 1
due: 20220909074424064
grade: 2
history: [{"due":"20220616065308998","interval":0,"difficulty":0.956170980055279,"stability":0.10092773437500001,"retrievability":1,"grade":-1,"lapses":0,"reps":1,"review":"20220615065308998"},{"due":"20220618004311413","interval":2,"difficulty":1.2801254823962773,"stability":0.07425364270040997,"retrievability":0.12395450234099842,"grade":0,"lapses":1,"reps":1,"review":"20220617004311412"},{"due":"20220620074958400","interval":2,"difficulty":1.5386766373737528,"stability":0.05491298557316543,"retrievability":0.05855115497747565,"grade":0,"lapses":2,"reps":1,"review":"20220619074958399"},{"due":"20220701140050857","interval":2,"difficulty":1,"stability":9.829205553538575,"retrievability":0.021550365655700003,"grade":2,"lapses":2,"reps":2,"review":"20220621140050857"}]
interval: 14
lapses: 2
modified: 20220705074424064
reps: 3
retrievability: 0.8606496253758356
review: 20220705074424064
stability: 65.66143979122012
tags: [[structed streaming]] ?
title: spark structed streaming sink触发间隔
type: text/vnd.tiddlywiki

我们前面跑Spark结构化流的时候，这个每一个批次的时间，都是Spark自行决定的。

| 触发类型                                                     | 描述                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| unspecified (default)不指定,默认方案                         | 如果没有明确指定触发设置，则默认情况下，查询将以微批处理模式执行，其中微批处理将在前一个微批处理完成后立即生成。 |
| Fixed interval micro-batches固定间隔微批次                   | 查询将以微批处理模式执行，其中微批处理将以用户指定的时间间隔启动。l 如果前一个微批处理在间隔内完成，则引擎将等待间隔结束，然后再启动下一个微批处理。l 如果前一个微批处理的完成时间比间隔时间长（即如果错过了一个间隔边界），那么下一个微批处理将在前一个完成后立即开始（即它不会等待下一个间隔边界）。l 如果没有新数据可用，则不会启动微批处理。 |
| One-time micro-batch一次性微批量                             | 仅执行一次, 在定期启动集群、处理自上一时期以来可用的所有内容然后关闭集群的情况下很有用。在某些情况下，这可能会显着节省成本。 |
| Continuous with fixed checkpoint interval (experimental)以固定检查点间隔连续, 目前为实验性 | 查询将以新的低延迟、连续处理模式执行, 不支持聚合操作 和固定时间间隔差不多，就是延迟更低了。 |

- unspecified:默认的，不指定，Spark自行决定多久是一个批次，同时Spark`自行决定`，尽可能快的完成一个批次。

- Fixed Interval：固定间隔的批次，比如设置为5秒，那么每隔5秒就是一个批次，`很固定`。

  设置方式：

  ```shell
  df.writeStream.\
      outputMode("update").\
      format("console").\
      trigger(processingTime="5 seconds").\
      start().awaitTermination()
  ```

  

- One-time：一次性的批次，启动程序后，执行一次结束。（很少用）

  ```shell
  rate_df.writeStream.\
      outputMode("update").\
      format("console").\
      trigger(once=True).\
      start().awaitTermination()
  ```

  ![image-20220612171944815](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/06/12/20220612171944.png)

  如图，跑一个第一个批次（批次0）就结束了

- Continuous：连续处理，和固定间隔是一个表现，延迟更低（spark的新功能，目前还是实验性，不稳妥）

  ```python
  rate_df.writeStream.\
      outputMode("update").\
      format("console").\
      trigger(continuous='5 seconds').\
      start().awaitTermination()
  # 效果依旧是固定5秒
  # 底层的执行和固定间隔不同，这个是新实现的功能，延迟会低很多
  # 目前不100%稳定
  ```



> 总结，在企业中一般会使用：
>
> 1. 默认的，让Spark自己决定批次间的间隔
> 2. 固定时间间隔，比如5秒一批

