created: 20220523033146222
difficulty: 1.688892224472874
due: 20230116064340373
grade: 1
history: [{"due":"20220524082110304","interval":0,"difficulty":3.7478003092274337,"stability":0.5750000000000001,"retrievability":1,"grade":-1,"lapses":0,"reps":1,"review":"20220523082110304"},{"due":"20220606012545593","interval":3,"difficulty":2.524919168615612,"stability":11.181919693641438,"retrievability":0.5771188593881783,"grade":2,"lapses":0,"reps":2,"review":"20220526012545593"},{"due":"20220729004756349","interval":14,"difficulty":1.6013358877257884,"stability":50.346949805680694,"retrievability":0.8764167191101764,"grade":2,"lapses":0,"reps":3,"review":"20220609004756349"}]
interval: 57
lapses: 0
modified: 20220805064340373
reps: 4
retrievability: 0.8875563367470857
review: 20220805064340372
stability: 164.10680035953874
tags: spark ?
title: executor,task和stage,job关系
type: text/vnd.tiddlywiki

executor和task关系：

一个executor可以并行执行多个task，实际上一个executor是一个进程，task是executor里的一个线程。

一个task至少要独占executor里的一个虚拟核心vcore。

一个executor里的核心数由spark-submit的--executor-cores参数指定。

一个task要占用几个核心，可以由.config("spark.task.cpus", 1)配置，默认是1即一个task占用一个vcore。

同时并行执行的task最大数量 = executor数目 * (每个executor核数 / 每个task占用核心数)

stage是横向的一条task,纵向并行的task数为分区数.一般一个分区的一个task是到shuffle为止

https://zhuanlan.zhihu.com/p/50752866

Job

spark中的数据都是抽象为RDD的，它支持两种类型的算子操作：Transformation和Action。Transformation算子的代码不会真正被执行。只有当我们的程序里面遇到一个action算子的时候，代码才会真正的被执行。

Transformation算子主要包括：map、mapPartitions、flatMap、filter、union、groupByKey、repartition、cache等。

Action算子主要包括：reduce、collect、show、count、foreach、saveAsTextFile等。

当在程序中遇到一个action算子的时候，就会提交一个job，执行前面的一系列操作。因此平时要注意，如果声明了数据需要cache或者persist，但在action操作前释放掉的话，该数据实际上并没有被缓存。

通常一个任务会有多个job，job之间是按照串行的方式执行的。一个job执行完成后，才会起下一个job。有一段时间曾想让job并行执行，但没有找到解决方法。

Stage

一个job通常包含一个或多个stage。各个stage之间按照顺序执行。上面已经说过，一个job会有多个算子操作。这些算子都是将一个父RDD转换成子RDD。这个过程中，会有两种情况：父RDD中的数据是否进入不同的子RDD。如果一个父RDD的数据只进入到一个子RDD，比如map、union等操作，称之为narrow dependency(窄依赖)。否则，就会形成wide dependency（ 宽依赖），一般也成为shuffle依赖，比如groupByKey等操作。

job中stage的划分就是根据shuffle依赖进行的。shuffle依赖是两个stage的分界点。shuffle操作一般都是任务中最耗时耗资源的部分。因为数据可能存放在HDFS不同的节点上，下一个stage的执行首先要去拉取上一个stage的数据（shuffle read操作），保存在自己的节点上，就会增加网络通信和IO。Shuffle操作其实是一个比较复杂的过程，这里暂且不表。

Task

一个spark application提交后，陆续被分解为job、stage，到这里其实还是一个比较粗的概念。Stage继续往下分解，就是Task。Task应该是spark最细的执行单元了。Task的数量其实就是stage的并行度。

RDD在计算的时候，每个分区都会起一个task，所以rdd的分区数目决定了总的的task数目。每个Task执行的结果就是生成了目标RDD的一个partiton。在Map阶段partition数目保持不变。在Reduce阶段，RDD的聚合会触发shuffle操作，聚合后的RDD的partition数目跟具体操作有关，例如repartition操作会聚合成指定分区数。coalesce算子同样可以改变partition的数目，不过只能减少不能增加。repartition和coalesce算子的区别在于前者会引发shuffle，后者则不会。

到这里，基本上介绍完了job、stage、task的一些特性。