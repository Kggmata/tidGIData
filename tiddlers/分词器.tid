created: 20220617015327517
difficulty: 1
due: 20221013075927336
grade: 2
history: [{"due":"20220620001937282","interval":0,"difficulty":0.6469164138781576,"stability":0.10005798339843751,"retrievability":1,"grade":-1,"lapses":0,"reps":1,"review":"20220619001937282"},{"due":"20220629000002348","interval":1,"difficulty":1,"stability":8.830517274901752,"retrievability":0.348891394928074,"grade":2,"lapses":0,"reps":2,"review":"20220620000002347"},{"due":"20220702122952707","interval":11,"difficulty":2.077002442148843,"stability":0.07408316441686115,"retrievability":0.8770024421488429,"grade":0,"lapses":1,"reps":1,"review":"20220701122952707"},{"due":"20220718092744319","interval":4,"difficulty":1,"stability":12.858890454366344,"retrievability":0.0033837533675606132,"grade":2,"lapses":1,"reps":2,"review":"20220705092744319"},{"due":"20220723030059802","interval":17,"difficulty":2.0699747575065692,"stability":0.054881225761675624,"retrievability":0.869974757506569,"grade":0,"lapses":2,"reps":1,"review":"20220722030059802"},{"due":"20220809032226457","interval":8,"difficulty":1,"stability":10.165658484204181,"retrievability":2.1377693640808248e-7,"grade":2,"lapses":2,"reps":2,"review":"20220730032226456"}]
interval: 13
lapses: 2
modified: 20220812075927336
reps: 3
retrievability: 0.8739460407178476
review: 20220812075927335
stability: 61.697530230673415
tags: 用户画像 ?
title: 分词器
type: text/vnd.tiddlywiki

中文

```
jieba

hanlp(Han Language Processing):
面向生产环境的多语种自然语言处理工具包，基于PyTorch和TensorFlow 2.x双引擎，目标是普及落地最前沿的NLP技术。

ik:
IK Analyzer是一个开源的，基于java语言开发的轻量级的中文分词工具包。从2006年12月推出1.0版开始， IKAnalyzer已经推出了4个大版本。最初，它是以开源项目Luence为应用主体的，结合词典分词和文法分析算法的中文分词组件。从3.0版本开始，IK发展为面向Java的公用分词组件，独立于Lucene项目，同时提供了对Lucene的默认优化实现。在2012版本中，IK实现了简单的分词歧义排除算法，标志着IK分词器从单纯的词典分词向模拟语义分词衍化。
```

英文

```
NLTK(Natural Language Toolkit)
```