created: 20220718131216881
creator: Yangqing QU
difficulty: 1
due: 20220831114531263
grade: 1
history: [{"due":"20220801121429313","interval":0,"difficulty":0.06011121757074328,"stability":0.10000002831220628,"retrievability":1,"grade":-1,"lapses":0,"reps":1,"review":"20220731121429313"},{"due":"20220808002256079","interval":7,"difficulty":1,"stability":0.07408182468994658,"retrievability":0.0006265800565729012,"grade":0,"lapses":1,"reps":1,"review":"20220807002256079"},{"due":"20220814091526208","interval":6,"difficulty":1.2001968026909542,"stability":0.05488116409496729,"retrievability":0.00019680269095417443,"grade":0,"lapses":2,"reps":1,"review":"20220813091526208"}]
interval: 8
lapses: 2
modified: 20221219145029022
modifier: Yangqing QU
reps: 2
retrievability: 2.13773247238443e-7
review: 20220821114531262
stability: 10.165649333901193
tags: ? spark
title: sparkSQL读取parquet, orc, json分区数量
type: text/vnd.tiddlywiki

```
spark.sql.files.maxPartitionBytes	

134217728 (128 MB)	
The maximum number of bytes to pack into a single partition when reading files. This configuration is effective only when using file-based sources such as Parquet, JSON and ORC.

spark.sql.files.minPartitionNum	

Default Parallelism	
The suggested (not guaranteed) minimum number of split file partitions. If not set, the default value is `spark.default.parallelism`. This configuration is effective only when using file-based sources such as Parquet, JSON and ORC.
```