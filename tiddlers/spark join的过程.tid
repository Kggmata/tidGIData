created: 20220615003856679
difficulty: 1
due: 20220912120822006
grade: 2
history: [{"due":"20220618143739154","interval":0,"difficulty":0.7341614645238075,"stability":0.10011596679687501,"retrievability":1,"grade":-1,"lapses":0,"reps":1,"review":"20220617143739154"},{"due":"20220620074833437","interval":2,"difficulty":1.0560352299673244,"stability":0.07412477722623134,"retrievability":0.12187376544351697,"grade":0,"lapses":1,"reps":1,"review":"20220619074833437"},{"due":"20220622135903668","interval":2,"difficulty":1.3142982288001035,"stability":0.054889119100343345,"retrievability":0.05826299883277926,"grade":0,"lapses":2,"reps":1,"review":"20220621135903667"},{"due":"20220704003039158","interval":3,"difficulty":1,"stability":10.116431491586642,"retrievability":0.003155694937719725,"grade":1,"lapses":2,"reps":2,"review":"20220624003039158"}]
interval: 14
lapses: 2
modified: 20221210005806777
modifier: Yangqing QU
reps: 3
retrievability: 0.8643244425328652
review: 20220708120822005
stability: 65.63897640829599
tags: userProfile用户画像 ?
title: spark join的过程
type: text/vnd.tiddlywiki

http://hbasefly.com/2017/03/19/sparksql-basic-join/
https://www.cnblogs.com/shendeng23/p/15240788.html

Join常见分类以及基本实现机制

当前SparkSQL支持三种Join算法－shuffle hash join、broadcast hash join以及sort merge join。

Hash Join

```
先来看看这样一条SQL语句：select * from order,item where item.id = order.i_id，很简单一个Join节点，参与join的两张表是item和order，join key分别是item.id以及order.i_id。现在假设这个Join采用的是hash join算法，整个过程会经历三步：

1. 确定Build Table以及Probe Table：这个概念比较重要，Build Table使用join key构建Hash Table，而Probe Table使用join key进行探测，探测成功就可以join在一起。通常情况下，小表会作为Build Table，大表作为Probe Table。此事例中item为Build Table，order为Probe Table。

2. 构建Hash Table：依次读取Build Table（item）的数据，对于每一行数据根据join key（item.id）进行hash，hash到对应的Bucket，生成hash table中的一条记录。数据缓存在内存中，如果内存放不下需要dump到外存。

3. 探测：再依次扫描Probe Table（order）的数据，使用相同的hash函数映射Hash Table中的记录，映射成功之后再检查join条件（item.id = order.i_id），如果匹配成功就可以将两者join在一起。
```
[img[0012022-06-15 08_39_38.png]]

基本流程可以参考上图，这里有两个小问题需要关注：

1. hash join性能如何？

```
很显然，hash join基本都只扫描两表一次，可以认为o(a+b)，较之最极端的笛卡尔集运算a*b，不知甩了多少条街
```

2. 为什么Build Table选择小表？

```
道理很简单，因为构建的Hash Table最好能全部加载在内存，效率最高；这也决定了hash join算法只适合至少一个小表的join场景，对于两个大表的join场景并不适用；

上文说过，hash join是传统数据库中的单机join算法，在分布式环境下需要经过一定的分布式改造，说到底就是尽可能利用分布式计算资源进行并行化计算，提高总体效率。hash join分布式改造一般有两种经典方案：
```

1. broadcast hash join：

```
将其中一张小表广播分发到另一张大表所在的分区节点上，分别并发地与其上的分区记录进行hash join。broadcast适用于小表很小，可以直接广播的场景。
```

2. shuffler hash join：

```
一旦小表数据量较大，此时就不再适合进行广播分发。这种情况下，可以根据join key相同必然分区相同的原理，将两张表分别按照join key进行重新组织分区，这样就可以将join分而治之，划分为很多小join，充分利用集群资源并行化。
```

Broadcast Hash Join

```
如下图所示，broadcast hash join可以分为两步：

1. broadcast阶段：将小表广播分发到大表所在的所有主机。广播算法可以有很多，最简单的是先发给driver，driver再统一分发给所有executor；要不就是基于bittorrete的p2p思路；

2. hash join阶段：在每个executor上执行单机版hash join，小表映射，大表试探；
```
[img[0022022-06-15 08_41_30.png]]

```
SparkSQL规定broadcast hash join执行的基本条件为被广播小表必须小于参数
spark.sql.autoBroadcastJoinThreshold，默认为10M。
```
Shuffle Hash Join

```
在大数据条件下如果一张表很小，执行join操作最优的选择无疑是broadcast hash join，效率最高。但是一旦小表数据量增大，广播所需内存、带宽等资源必然就会太大，broadcast hash join就不再是最优方案。此时可以按照join key进行分区，根据key相同必然分区相同的原理，就可以将大表join分而治之，划分为很多小表的join，充分利用集群资源并行化。如下图所示，shuffle hash join也可以分为两步：

1. shuffle阶段：分别将两个表按照join key进行分区，将相同join key的记录重分布到同一节点，两张表的数据会被重分布到集群中所有节点。这个过程称为shuffle

2. hash join阶段：每个分区节点上的数据单独执行单机hash join算法。
```
[img[0032022-06-15 08_42_20.png]]

```
看到这里，可以初步总结出来如果两张小表join可以直接使用单机版hash join；如果一张大表join一张极小表，可以选择broadcast hash join算法；而如果是一张大表join一张小表，则可以选择shuffle hash join算法；那如果是两张大表进行join呢？
```

Sort-Merge Join

SparkSQL对两张大表join采用了全新的算法－sort-merge join，如下图所示，整个过程分为三个步骤：

[img[0042022-06-15 08_43_00.png]]

```
1. shuffle阶段：将两张大表根据join key进行重新分区，两张表数据会分布到整个集群，以便分布式并行处理

2. sort阶段：对单个分区节点的两表数据，分别进行排序

3. merge阶段：对排好序的两张分区表数据执行join操作。join操作很简单，分别遍历两个有序序列，碰到相同join key就merge输出，否则取更小一边，见下图示意：
```

[img[0052022-06-15 08_43_02.png]]

```
仔细分析的话会发现，sort-merge join的代价并不比shuffle hash join小，反而是多了很多。那为什么SparkSQL还会在两张大表的场景下选择使用sort-merge join算法呢？这和Spark的shuffle实现有关，目前spark的shuffle实现都适用sort-based shuffle算法，因此在经过shuffle之后partition数据都是按照key排序的。因此理论上可以认为数据经过shuffle之后是不需要sort的，可以直接merge。

经过上文的分析，可以明确每种Join算法都有自己的适用场景，数据仓库设计时最好避免大表与大表的join查询，SparkSQL也可以根据内存资源、带宽资源适量将参数spark.sql.autoBroadcastJoinThreshold调大，让更多join实际执行为broadcast hash join。
```

总结

```
Join操作是传统数据库中的一个高级特性，尤其对于当前MySQL数据库更是如此，原因很简单，MySQL对Join的支持目前还比较有限，只支持Nested-Loop Join算法，因此在OLAP场景下MySQL是很难吃的消的，不要去用MySQL去跑任何OLAP业务，结果真的很难看。不过好消息是MySQL在新版本要开始支持Hash Join了，这样也许在将来也可以用MySQL来处理一些小规模的OLAP业务。


和MySQL相比，PostgreSQL、SQLServer、Oracle等这些数据库对Join支持更加全面一些，都支持Hash Join算法。由PostgreSQL作为内核构建的分布式系统Greenplum更是在数据仓库中占有一席之地，这和PostgreSQL对Join算法的支持其实有很大关系。


总体而言，传统数据库单机模式做Join的场景毕竟有限，也建议尽量减少使用Join。然而大数据领域就完全不同，Join是标配，OLAP业务根本无法离开表与表之间的关联，对Join的支持成熟度一定程度上决定了系统的性能，夸张点说，’得Join者得天下’。本文只是试图带大家真正走进Join的世界，了解常用的几种Join算法以及各自的适用场景。后面两篇文章还会涉及Join的方方面面，敬请期待！
```