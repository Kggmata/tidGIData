created: 20220521022624916
difficulty: 1.7246019714021352
due: 20220910111331807
grade: 2
history: [{"due":"20220523083739496","interval":0,"difficulty":5,"stability":2,"retrievability":1,"grade":-1,"lapses":0,"reps":1,"review":"20220521083739496"},{"due":"20220529002957168","interval":2,"difficulty":4.1000000000000005,"stability":6.091873624375545,"retrievability":0.9,"grade":2,"lapses":0,"reps":2,"review":"20220523002957168"},{"due":"20220603074041920","interval":10,"difficulty":5.141177516867769,"stability":0.0960748629946603,"retrievability":0.8411775168677682,"grade":0,"lapses":1,"reps":1,"review":"20220602074041920"},{"due":"20220613122332660","interval":4,"difficulty":3.353620471438025,"stability":6.74717735579917,"retrievability":0.012442954570255769,"grade":2,"lapses":1,"reps":2,"review":"20220606122332660"},{"due":"20220713061756395","interval":9,"difficulty":2.422509852047999,"stability":27.58643586331761,"retrievability":0.8688893806099739,"grade":2,"lapses":1,"reps":3,"review":"20220615061756395"},{"due":"20220722013059986","interval":36,"difficulty":3.4940491421561477,"stability":0.054881287913948605,"retrievability":0.8715392901081483,"grade":0,"lapses":2,"reps":1,"review":"20220721013059986"},{"due":"20220804025953141","interval":9,"difficulty":2.694049173504481,"stability":5.107321683801711,"retrievability":3.1348333116598453e-8,"grade":1,"lapses":2,"reps":2,"review":"20220730025953141"}]
interval: 9
lapses: 2
modified: 20221210010743381
modifier: Yangqing QU
reps: 3
retrievability: 0.8305527978976539
review: 20220808111331807
stability: 32.992436917050085
tags: [[hdfs(hadoop distributed file system)]] ?
title: HDFS的存储机制（读写流程）
type: text/vnd.tiddlywiki

HDFS存储机制，包括HDFS的写入过程和读取过程两个部分
[img[Snipaste_2022-06-02_13-38-39.jpg]]

1）客户端向namenode请求上传文件，namenode检查目标文件是否已存在，父目录是否存在。

2）namenode返回是否可以上传。

3）客户端请求第一个 block上传到哪几个datanode服务器上。

4）namenode根据副本机制返回3个datanode节点，分别为dn1、dn2、dn3。

5）客户端请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。

6）dn1、dn2、dn3逐级应答客户端

7）客户端开始往dn1上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位，dn1

收到一个packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答

8）当一个block传输完成之后，客户端再次请求namenode上传第二个block的服务器。（重复执行3-7步）

HDFS  写入数据流程中出现问题，内部的操作

[img[Snipaste_2022-06-02_13-39-42.jpg]]

读取:

[img[Snipaste_2022-06-02_13-39-06.jpg]]

1）客户端向namenode请求下载文件，namenode通过查询元数据，找到文件块所在的datanode地址。

2）挑选一台datanode（就近原则，然后随机）服务器，请求读取数据。

3）datanode开始传输数据给客户端（从磁盘里面读取数据放入流，以packet为单位来做校验）。

4）客户端以packet为单位接收，先在本地缓存，然后写入目标文件。

并行读

pipeline是什么？ pipeline，中文意为管线，意义等同于流水线
