created: 20220718130019466
difficulty: 1
due: 20230425125342759
grade: 1
history: [{"due":"20220801121147384","interval":0,"difficulty":0.06011121757074328,"stability":0.10000002831220628,"retrievability":1,"grade":-1,"lapses":0,"reps":1,"review":"20220731121147384"},{"due":"20220822123602533","interval":6,"difficulty":1,"stability":16.39335325161452,"retrievability":0.0017970135161932011,"grade":2,"lapses":0,"reps":2,"review":"20220806123602533"}]
interval: 54
lapses: 0
modified: 20220929125342759
reps: 3
retrievability: 0.7067633236242729
review: 20220929125342759
stability: 207.96630844006646
tags: ?
title: 数据倾斜的原因
type: text/vnd.tiddlywiki

```
在进行 shuffle 的时候，必须将各个节点上相同的 key 拉取到某个节点上的一个 task 来进行处理，比如按照 key 进行聚合或 join 等操作。此时如果某个 key 对应的数据量特别大的话，就会发生数据倾斜。比如大部分 key 对应10条数据，但是个别 key 却对应了100万条数据，那么大部分 task 可能就只会分配到10条数据，然后1秒钟就运行完了；但是个别 task 可能分配到了100万数据，要运行一两个小时。

因此出现数据倾斜的时候，Spark 作业看起来会运行得非常缓慢，甚至可能因为某个 task 处理的数据量过大导致内存溢出。
```